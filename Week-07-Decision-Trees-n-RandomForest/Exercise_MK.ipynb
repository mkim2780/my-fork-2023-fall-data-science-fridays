{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function to split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Helper fuctions to evaluate our model.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "\n",
    "# Import our Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Import our Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import the trees from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Helper functions to visualize our trees\n",
    "from sklearn.tree import plot_tree, export_text# Import our libraries \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Steps when building a Machine Learning Model. \n",
    "1. Inspect and explore data.\n",
    "2. Select and engineer features.\n",
    "3. Build and train model.\n",
    "4. Evaluate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1 Inspect and explore data.\n",
    "* Load titanic data\n",
    "* Visualize all the data using sns.pairplot\n",
    "* Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'sex', 'age', 'sibsp',\n",
       "       'parch', 'ticket', 'fare', 'cabin', 'embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the titanic data set.\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "df.head()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all the data using sns.pairplot\n",
    "sns.pairplot(df, hue = 'pclass', markers=[\"o\", \"s\", \"D\"], palette=\"husl\")\n",
    "plt.show()\n",
    "#how different variables are distributed or related within each passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2 Select and engineer features.\n",
    "1. Fill age null values with -999\n",
    "1. Convert to numerical values if need be by using `pd.get_dummies()`\n",
    "1. Create a list of the features you are going to use.  In this case use as many or as little as you would like.\n",
    "1. Define our `X` and `y`\n",
    "1. Split our data into trainig and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       22.0\n",
       "1       38.0\n",
       "2       26.0\n",
       "3       35.0\n",
       "4       35.0\n",
       "       ...  \n",
       "886     27.0\n",
       "887     19.0\n",
       "888   -999.0\n",
       "889     26.0\n",
       "890     32.0\n",
       "Name: age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill age null values with -999\n",
    "df['age'].fillna(-999, inplace = True)\n",
    "df.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passengerid  survived  pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  name    age  sibsp  parch  \\\n",
       "0                              Braund, Mr. Owen Harris   22.0      1      0   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...   38.0      1      0   \n",
       "2                               Heikkinen, Miss. Laina   26.0      0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)   35.0      1      0   \n",
       "4                             Allen, Mr. William Henry   35.0      0      0   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "886                              Montvila, Rev. Juozas   27.0      0      0   \n",
       "887                       Graham, Miss. Margaret Edith   19.0      0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\" -999.0      1      2   \n",
       "889                              Behr, Mr. Karl Howell   26.0      0      0   \n",
       "890                                Dooley, Mr. Patrick   32.0      0      0   \n",
       "\n",
       "               ticket     fare cabin embarked  sex_male  \n",
       "0           A/5 21171   7.2500   NaN        S         1  \n",
       "1            PC 17599  71.2833   C85        C         0  \n",
       "2    STON/O2. 3101282   7.9250   NaN        S         0  \n",
       "3              113803  53.1000  C123        S         0  \n",
       "4              373450   8.0500   NaN        S         1  \n",
       "..                ...      ...   ...      ...       ...  \n",
       "886            211536  13.0000   NaN        S         1  \n",
       "887            112053  30.0000   B42        S         0  \n",
       "888        W./C. 6607  23.4500   NaN        S         0  \n",
       "889            111369  30.0000  C148        C         1  \n",
       "890            370376   7.7500   NaN        Q         1  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Convert to numerical values if need be by using `pd.get_dummies()`\n",
    "df = pd.get_dummies(df,columns=[\"sex\"], drop_first= True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a list of the features we are going to use.\n",
    "selected_features = [\"fare\", \"sex_male\"]\n",
    "\n",
    "# Set X to be the features we are going to use.\n",
    "X = df[selected_features]\n",
    "\n",
    "# Set y to be our target variable. \n",
    "y = df[\"survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our `X` and `y`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 2) (179, 2)\n",
      "Lenght of our Training data: (712, 2) \n",
      "Length of our Testing data: (179, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split our data into trainig and testing sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2)\n",
    "\n",
    "# Print the length and width of our testing data.\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "print('Lenght of our Training data: ' + str(X_train.shape), '\\nLength of our Testing data: ' + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3 Build and train model.\n",
    "1. For our first pass, initialize our model with `max_depth=2`.\n",
    "2. Fit our model with our training data. \n",
    "3. Make predictions of our testing data. \n",
    "4. Evaluate and print our model scores using accuracy, precision, recall, f1 scores, and auc scores. \n",
    "    * To calculate auc score you have to get the predicted probabilites for the Survived class using `model.predict_proba(X_test)[:,1]`\n",
    "5. Visualize our Decision Tree using provided code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our first pass, initialize our model with `max_depth=2`.\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m X_train \u001b[39m=\u001b[39m [[\u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfare\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpclass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msibsp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mparch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39membarked\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m y_train \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msurvived\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit our model with our training data. \n",
    "\n",
    "X_train = [['age', 'fare', 'pclass', 'sex', 'sibsp', 'parch', 'embarked']]\n",
    "\n",
    "y_train = ['survived']\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of our testing data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate and print our model scores using accuracy, precision, recall, f1 scores, and auc scores. \n",
    "accuracy = ???\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = ???\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = ???\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = ???\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities\n",
    "y_pred_proba = model.predict_proba(???)\n",
    "\n",
    "# Keep only the proba for True\n",
    "y_pred_proba = y_pred_proba[:,1]\n",
    "\n",
    "# Compute auc score\n",
    "auc = ???\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize your tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking the right parameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning of your Decision Tree using GridSearch or RandomizedSearch\n",
    "\n",
    "### For assistance on this, look at Steves TA Tips code in `TA-Tips/random_forest_tuning.ipynb`\n",
    "\n",
    "\n",
    "1. Make a dictionary of at least 3 parameters and a list of 3 values for each for your grid search. \n",
    "1. Initalize your GridSearchCV with a DecisionTreeClassifier, your param_grid, and what you are optimizing for.  Choose any of the five optimization strategies; accuracy, precision, recall, f1, or roc_auc.\n",
    "1. Fit your GridSearchCV with your training data. \n",
    "1. Print the parameters of your best model. \n",
    "1. Evaluate your best model using accuracy, precision, recall, f1 scores, and auc scores. \n",
    "1. Visualize your best tree.\n",
    "1. Which feature was your most important feature?\n",
    "\n",
    "```python\n",
    "tree.DecisionTreeClassifier(\n",
    "    *,\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort='deprecated',\n",
    "    ccp_alpha=0.0,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tips on how to customize / set the paramters in the decision tree.](https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1. Make a dictionary of at least 3 parameters and a list of 3 values for each for your grid search.from sklearn.model_selection import GridSearchCV\n",
    "params = { \n",
    "    'PARAMETER_NAME': ['LIST', 'OF', 'VALUES'], ??? }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initalize your GridSearchCV with a DecisionTreeClassifier, your param_grid, and what you are optimizing for.  Choose any of the five optimization strategies; accuracy, precision, recall, f1, or roc_auc.\n",
    "grid_search_cv =  GridSearchCV( ??? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit your GridSearchCV with your training data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Print the parameters of your best model. \n",
    "# Print the best parameters it found\n",
    "print( ??? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Evaluate your best model using accuracy, precision, recall, f1 scores, and auc scores. \n",
    "\n",
    "# This command gives you the best tree\n",
    "model = ???\n",
    "\n",
    "# Now lets evaluate our model\n",
    "y_pred = ???\n",
    "\n",
    "accuracy = ???\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = ???\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = ???\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = ???\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(???)[:,1]\n",
    "auc = ???\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Which feature was your most important feature?\n",
    "# Now lets look at our feature importances\n",
    "feature_imp = pd.DataFrame.from_dict( {'feature_importance': model.feature_importances_,\n",
    "                                       'feature':selected_features }).sort_values('feature_importance', ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now onto Random Forests...\n",
    "Were going to do the same with, but this time with a random forest. Remeber... Repetition is the father of learning.\n",
    "\n",
    "1. Make a dictionary of at least 3 parameters and a list of 3 values for each for your grid search. \n",
    "1. Initalize your GridSearchCV with a RandomForestClassifer, your param_grid, and what you are optimizing for.  Choose any of the five optimization strategies; accuracy, precision, recall, f1, or roc_auc.\n",
    "1. Fit your GridSearchCV with your training data. \n",
    "1. Print the parameters of your best model. \n",
    "1. Evaluate your best model using accuracy, precision, recall, f1 scores, and auc scores. \n",
    "1. Which feature was your most important feature?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters of the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    *,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make a dictionary of at least 3 parameters and a list of 3 values for each for your grid search. \n",
    "params = {\n",
    "    'PARAMETER_1_NAME': ['LIST', 'OF', 'VALUES'], \n",
    "    'PARAMETER_2_NAME': ['LIST', 'OF', 'VALUES'],\n",
    "    'PARAMETER_3_NAME': ['LIST', 'OF', 'VALUES'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initalize your GridSearchCV or RandomizedSearchCV with a RandomForestClassifer, your param_grid, and what you are optimizing for.  Choose any of the five optimization strategies; accuracy, precision, recall, f1, or roc_auc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit your GridSearchCV with your training data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Print the parameters of your best model. \n",
    "# Print the best parameters it found\n",
    "print(???)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Evaluate your best model using accuracy, precision, recall, f1 scores, and auc scores. \n",
    "\n",
    "# This command gives you tree that has the highest f1-score. \n",
    "model = grid_search_cv.best_estimator_\n",
    "\n",
    "\n",
    "# Now lets evaluate our model\n",
    "y_pred = ???\n",
    "\n",
    "accuracy = ???\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = ???\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = ???\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = ???\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc = ???\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Which feature was your most important feature?\n",
    "# Now lets look at our feature importances\n",
    "feature_imp = pd.Series(model.feature_importances_,index=selected_features).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a random forest using the ny-vs-sf-housing.csv data. \n",
    "* Your target variable, aka the column you are trying to predict, aka your `y` variable is `in_sf`. \n",
    "* Can you get an accuracy above %88.8889?\n",
    "* What was your most important feature?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ny-vs-sf-houses.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD, TRAIN, AND EVAULATE A RANDOM FOREST MODEL BELOW. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome difficult extra credit below:\n",
    "Build a classifier using the adult_income.csv data.  \n",
    "* The target variable is 'class'\n",
    "* Start with just using these features `selected_features = ['age', 'fnlwgt', 'capital_gain', 'capital_loss', 'hours_per_week']`\n",
    "* You have to include the pos_label in your precision, recall, and f1 scores. It just tells the classifier which one is the posotive label.  I provided the proper way below.\n",
    "\n",
    "* See if you can get above 50% f1 score.  \n",
    "* See some [super tricks and tips here](https://www.kaggle.com/code/jieyima/income-classification-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult_income.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
